{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie_Recommendations.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPid6ROWH39PGGQg6rMAac/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayukh776/Projects/blob/master/Movie_Recommendations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgiILWhdZKMK",
        "colab_type": "text"
      },
      "source": [
        "# Boltzmann Machines\n",
        "\n",
        "## Notebook Details\n",
        "- __notebook name__: `'Movie_Recommendations'\n",
        "- __notebook version/date__: `1.0.0`/`17-04-20`\n",
        "- __notebook server__: Google Colab\n",
        "- __python version__: `3.6`\n",
        "- __pytorch version__: `1.1.0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIeTPByMXeIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.utils.data\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n35XsG4ziNBv",
        "colab_type": "text"
      },
      "source": [
        "The following dataset contains a list of 3952 movies along with their Genre which is instrumental in determining a user's preference for a particular movie. Viewers are more likely to enjoy a movie more similar to the genre they are accustomed to viewing. For instance, if a viewer emjoyed The Godfather it might be possible that it is because he/she likes Drama movies in general. So there is a higher probability of him/her to like another Drama - The Goodfellas than an adventure film like Jumanji.Just like Genre, there might be other factors in asserting whether a person would enjoy a certain movie or not like \n",
        "- whether the film won an Oscar\n",
        "- who is the Director ?\n",
        "- Who is the lead Actor ?  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHnJ8kYtapeE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "0e1555d6-d55a-466f-d8bb-51c1b8bbb40a"
      },
      "source": [
        "# Importing the datasets\n",
        "movies_headers = ['MOVIE_ID','TITLE','GENRE']\n",
        "movies = pd.read_csv('movies.dat',sep ='::',header=None,engine='python',encoding='latin-1').values\n",
        "movies = pd.DataFrame(movies,columns=movies_headers)\n",
        "movies = movies.set_index(['MOVIE_ID'])\n",
        "print(movies.head(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                        TITLE                         GENRE\n",
            "SERIAL_NO                                                                  \n",
            "1                            Toy Story (1995)   Animation|Children's|Comedy\n",
            "2                              Jumanji (1995)  Adventure|Children's|Fantasy\n",
            "3                     Grumpier Old Men (1995)                Comedy|Romance\n",
            "4                    Waiting to Exhale (1995)                  Comedy|Drama\n",
            "5          Father of the Bride Part II (1995)                        Comedy\n",
            "6                                 Heat (1995)         Action|Crime|Thriller\n",
            "7                              Sabrina (1995)                Comedy|Romance\n",
            "8                         Tom and Huck (1995)          Adventure|Children's\n",
            "9                         Sudden Death (1995)                        Action\n",
            "10                           GoldenEye (1995)     Action|Adventure|Thriller\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p_GhIO_9tKc",
        "colab_type": "text"
      },
      "source": [
        "Given below are the list of all the users (who will give their ratings) along with all their details which are not much of use apart from uniquely identifying the users."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epIAfS8XX67s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "6ce01cac-2b6c-4f8e-80d1-7f55c08bcc8c"
      },
      "source": [
        "user_headers = ['USER_NO','GENDER','AGE','OCCUPATION_CODE','VISIT_CODE']\n",
        "users = pd.read_csv('users.dat',sep ='::',header = None,engine='python',encoding='latin-1').values\n",
        "users = pd.DataFrame(users,columns=user_headers)\n",
        "users = users.set_index(['USER_NO'])\n",
        "print(users.head(10))   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          GENDER AGE OCCUPATION_CODE VISIT_CODE\n",
            "SERIAL_NO                                      \n",
            "1              F   1              10      48067\n",
            "2              M  56              16      70072\n",
            "3              M  25              15      55117\n",
            "4              M  45               7      02460\n",
            "5              M  25              20      55455\n",
            "6              F  50               9      55117\n",
            "7              M  35               1      06810\n",
            "8              M  25              12      11413\n",
            "9              M  25              17      61614\n",
            "10             F  35               1      95370\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6EzhBMLEkHc",
        "colab_type": "text"
      },
      "source": [
        "Given below is the list of all the ratings given by each user for each and every movie he/she has watched. The ratings are from 1 to 5. We shall use this dataset to train our Boltzmann machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_rPk8_2X7Kh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "2f89778f-6d2c-491c-d351-e7a5b510a43d"
      },
      "source": [
        "ratings_headers = ['USER_NO','MOVIE_ID','RATINGS','TIME_STAMPS']\n",
        "ratings = pd.read_csv('ratings.dat',sep ='::',header = None,engine='python',encoding='latin-1').values\n",
        "ratings = pd.DataFrame(ratings,columns=ratings_headers)\n",
        "ratings = ratings.set_index(['USER_NO'])\n",
        "print(ratings.head(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         MOVIE_ID  RATINGS  TIME_STAMPS\n",
            "USER_NO                                \n",
            "1            1193        5    978300760\n",
            "1             661        3    978302109\n",
            "1             914        3    978301968\n",
            "1            3408        4    978300275\n",
            "1            2355        5    978824291\n",
            "1            1197        3    978302268\n",
            "1            1287        5    978302039\n",
            "1            2804        5    978300719\n",
            "1             594        4    978302268\n",
            "1             919        4    978301368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCbQSl7AfrMe",
        "colab_type": "text"
      },
      "source": [
        "# Boltzmann Machines - Principle and Working\n",
        "A Boltzmann machine  is a type of stochastic recurrent neural network.\n",
        "Although learning is impractical in general Boltzmann machines, it can be made quite efficient in a restricted Boltzmann machine (RBM) which does not allow intralayer connections between hidden units. After training one RBM, the activities of its hidden units can be treated as data for training a higher-level RBM. This method of stacking RBMs makes it possible to train many layers of hidden units efficiently and is one of the most common deep learning strategies. As each new layer is added the generative model improves.\n",
        "An extension to the restricted Boltzmann machine allows using real valued data rather than binary data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLMH3ZoIaJwf",
        "colab_type": "text"
      },
      "source": [
        "# TEST SET I"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K_H7mmgFz78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "9504348d-fc79-452d-a1d7-66ea7882770d"
      },
      "source": [
        "# Preparing the training sets and test sets\n",
        "training_set = pd.read_csv('u1.base',delimiter='\\t')\n",
        "training_set = np.array(training_set,dtype='int')\n",
        "test_set = pd.read_csv('u1.test',delimiter='\\t')\n",
        "test_set = np.array(test_set,dtype='int')\n",
        "print(training_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[        1         2         3 876893171]\n",
            " [        1         3         4 878542960]\n",
            " [        1         4         3 876893119]\n",
            " ...\n",
            " [      943      1188         3 888640250]\n",
            " [      943      1228         3 888640275]\n",
            " [      943      1330         3 888692465]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNByiQbgWqRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
        "no_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zcyKb-Orj0Lf",
        "colab": {}
      },
      "source": [
        "# Converting the data into a matrix with users in lines and movies in columns\n",
        "def convert(data):\n",
        "  new_data = []\n",
        "  for id_users in range(1,no_users + 1):\n",
        "    id_movies = data[:,1][data[:,0] == id_users]\n",
        "    id_ratings = data[:,2][data[:,0] == id_users]\n",
        "    ratings = np.zeros(no_movies)\n",
        "    ratings[id_movies-1] = id_ratings\n",
        "    new_data.append(list(ratings))\n",
        "  return new_data\n",
        "training_set_list = convert(training_set)\n",
        "test_set_list = convert(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doDW4SA0uH6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Torch Tensors\n",
        "# Input for a Tensor would be a list of lists \n",
        "training_set_list = torch.FloatTensor(training_set_list)\n",
        "test_set_list = torch.FloatTensor(test_set_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1fvGvIju_-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set_list[training_set_list == 0] = -1\n",
        "training_set_list[training_set_list == 1] = 0\n",
        "training_set_list[training_set_list == 2] = 0\n",
        "training_set_list[training_set_list >= 3] = 1\n",
        "test_set_list[test_set_list == 0] = -1\n",
        "test_set_list[test_set_list == 1] = 0\n",
        "test_set_list[test_set_list == 2] = 0\n",
        "test_set_list[test_set_list >= 3] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBOecnR-xVSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the architecture of the RBM\n",
        "class RBM():\n",
        "  def __init__(self,nv,nh):\n",
        "    # Initializes the weights of the probs for the visible node given the hidden nodes\n",
        "    self.W = torch.randn(nh,nv) \n",
        "    # Initializes the bias of the probs for the hidden node\n",
        "    self.A = torch.randn(1,nh) \n",
        "    # Initializes the bias of the probs for the visible node\n",
        "    self.B = torch.randn(1,nv) \n",
        "  # Sampling the hidden nodes according to probs P(H/V)\n",
        "  def sample_h(self,x):\n",
        "    # Product of W and x\n",
        "    wx = torch.mm(x,self.W.t())\n",
        "    # To have the same dimensionality as wx appiled at each line of mininbatch wx.\n",
        "    activation = wx + self.A.expand_as(wx) \n",
        "    p_h_given_v = torch.sigmoid(activation)\n",
        "    # Returns bernoulli samples of p_h_given_v distribution\n",
        "    return p_h_given_v,torch.bernoulli(p_h_given_v)\n",
        "  # Sampling the visible nodes according to probs P(V/H)\n",
        "  def sample_v(self,y):\n",
        "    wy = torch.mm(y,self.W) # Product of W and x\n",
        "    activation = wy + self.B.expand_as(wy) # To have the same dimensionality as wx\n",
        "    p_v_given_h = torch.sigmoid(activation)\n",
        "    return p_v_given_h,torch.bernoulli(p_v_given_h)\n",
        "  # Contrastive Divergence\n",
        "  def train(self,v0,vk,ph0,phk):\n",
        "    self.W = self.W + (torch.mm(v0.t(),ph0) - torch.mm(vk.t(),phk)).t()\n",
        "    self.B = self.B + torch.sum((v0 - vk),0)\n",
        "    self.A = self.A + torch.sum((ph0 - phk),0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x62k357FE3fS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "12c54380-752b-4665-e96d-ca3ff8ee155e"
      },
      "source": [
        "# no of movies\n",
        "nv = len(training_set_list[0])\n",
        "# no of features we want to detect\n",
        "nh = 100\n",
        "batch_size = 100\n",
        "# Creating the object\n",
        "rbm = RBM(nv,nh)\n",
        "# Training the RBM\n",
        "no_epoch = 10\n",
        "for epoch in range(1,no_epoch + 1):\n",
        "    train_loss = 0 # diff b/w pred and actual ratings\n",
        "    s = 0.0\n",
        "    for id_users in range(0,no_users - batch_size,batch_size):\n",
        "        vk = training_set_list[id_users:id_users + batch_size]\n",
        "        v0 = training_set_list[id_users:id_users + batch_size]  # Actual ratings\n",
        "        ph0,_ = rbm.sample_h(v0)\n",
        "        # K-step Contrastive Divergence\n",
        "        for k in range(10):\n",
        "            _,hk = rbm.sample_h(vk)\n",
        "            _,vk = rbm.sample_v(hk)\n",
        "            vk[v0<0] = v0[v0<0]\n",
        "        phk,_ = rbm.sample_h(vk)\n",
        "        rbm.train(v0,vk,ph0,phk)\n",
        "        train_loss += torch.mean(torch.abs(v0[v0>=0]-vk[v0>=0]))\n",
        "        s+=1\n",
        "    print('epoch: ' + str(epoch) + ' loss: ' + str(train_loss/s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 loss: tensor(0.3327)\n",
            "epoch: 2 loss: tensor(0.2470)\n",
            "epoch: 3 loss: tensor(0.2527)\n",
            "epoch: 4 loss: tensor(0.2485)\n",
            "epoch: 5 loss: tensor(0.2507)\n",
            "epoch: 6 loss: tensor(0.2460)\n",
            "epoch: 7 loss: tensor(0.2463)\n",
            "epoch: 8 loss: tensor(0.2479)\n",
            "epoch: 9 loss: tensor(0.2447)\n",
            "epoch: 10 loss: tensor(0.2488)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdlaorwyGVmo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d806d9a-b374-4757-b839-64ac6071a299"
      },
      "source": [
        "# diff b/w pred and actual ratings\n",
        "test_loss = 0 \n",
        "s = 0.0\n",
        "for id_users in range(no_users):\n",
        "    v = training_set_list[id_users:id_users + 1]\n",
        "    vt = test_set_list[id_users:id_users + 1]  # Actual ratings\n",
        "    if len(vt[vt>=0])>0:\n",
        "        _,h = rbm.sample_h(v)\n",
        "        _,v = rbm.sample_v(h)\n",
        "        test_loss += torch.mean(torch.abs(vt[vt>=0]-v[vt>=0]))\n",
        "        s+=1\n",
        "print('test loss:' + str(test_loss/s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test loss:tensor(0.2464)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_jMrUGGaXby",
        "colab_type": "text"
      },
      "source": [
        "# TEST SET II"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g2nN5nBj58l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "124ecca8-5c86-4f91-e266-b2563396d89e"
      },
      "source": [
        "# Preparing the training sets and test sets\n",
        "training_set = pd.read_csv('u2.base',delimiter='\\t')\n",
        "training_set = np.array(training_set,dtype='int')\n",
        "test_set = pd.read_csv('u2.test',delimiter='\\t')\n",
        "test_set = np.array(test_set,dtype='int')\n",
        "print(training_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[        1         4         3 876893119]\n",
            " [        1         5         3 889751712]\n",
            " [        1         6         5 887431973]\n",
            " ...\n",
            " [      943      1188         3 888640250]\n",
            " [      943      1228         3 888640275]\n",
            " [      943      1330         3 888692465]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgWrf-1lXF-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
        "no_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjczqCR5j6iZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the data into a matrix with users in lines and movies in columns\n",
        "def convert(data):\n",
        "  new_data = []\n",
        "  for id_users in range(1,no_users + 1):\n",
        "    id_movies = data[:,1][data[:,0] == id_users]\n",
        "    id_ratings = data[:,2][data[:,0] == id_users]\n",
        "    ratings = np.zeros(no_movies)\n",
        "    ratings[id_movies-1] = id_ratings\n",
        "    new_data.append(list(ratings))\n",
        "  return new_data\n",
        "training_set_list = convert(training_set)\n",
        "test_set_list = convert(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mabc5PgHj6nT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Torch Tensors\n",
        "# Input for a Tensor would be a list of lists \n",
        "training_set_list = torch.FloatTensor(training_set_list)\n",
        "test_set_list = torch.FloatTensor(test_set_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YSzvKkCj6sQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set_list[training_set_list == 0] = -1\n",
        "training_set_list[training_set_list == 1] = 0\n",
        "training_set_list[training_set_list == 2] = 0\n",
        "training_set_list[training_set_list >= 3] = 1\n",
        "test_set_list[test_set_list == 0] = -1\n",
        "test_set_list[test_set_list == 1] = 0\n",
        "test_set_list[test_set_list == 2] = 0\n",
        "test_set_list[test_set_list >= 3] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJuJR2VEj6vO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the architecture of the RBM\n",
        "class RBM():\n",
        "  def __init__(self,nv,nh):\n",
        "    # Initializes the weights of the probs for the visible node given the hidden nodes\n",
        "    self.W = torch.randn(nh,nv) \n",
        "    # Initializes the bias of the probs for the hidden node\n",
        "    self.A = torch.randn(1,nh) \n",
        "    # Initializes the bias of the probs for the visible node\n",
        "    self.B = torch.randn(1,nv) \n",
        "  # Sampling the hidden nodes according to probs P(H/V)\n",
        "  def sample_h(self,x):\n",
        "    # Product of W and x\n",
        "    wx = torch.mm(x,self.W.t())\n",
        "    # To have the same dimensionality as wx appiled at each line of mininbatch wx.\n",
        "    activation = wx + self.A.expand_as(wx) \n",
        "    p_h_given_v = torch.sigmoid(activation)\n",
        "    # Returns bernoulli samples of p_h_given_v distribution\n",
        "    return p_h_given_v,torch.bernoulli(p_h_given_v)\n",
        "  # Sampling the visible nodes according to probs P(V/H)\n",
        "  def sample_v(self,y):\n",
        "    wy = torch.mm(y,self.W) # Product of W and x\n",
        "    activation = wy + self.B.expand_as(wy) # To have the same dimensionality as wx\n",
        "    p_v_given_h = torch.sigmoid(activation)\n",
        "    return p_v_given_h,torch.bernoulli(p_v_given_h)\n",
        "  # Contrastive Divergence\n",
        "  def train(self,v0,vk,ph0,phk):\n",
        "    self.W = self.W + (torch.mm(v0.t(),ph0) - torch.mm(vk.t(),phk)).t()\n",
        "    self.B = self.B + torch.sum((v0 - vk),0)\n",
        "    self.A = self.A + torch.sum((ph0 - phk),0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SIwhdzrj62a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "3ee02bc4-3091-4a4f-839a-87905e1658f1"
      },
      "source": [
        "# no of movies\n",
        "nv = len(training_set_list[0])\n",
        "# no of features we want to detect\n",
        "nh = 100\n",
        "batch_size = 100\n",
        "# Creating the object\n",
        "rbm = RBM(nv,nh)\n",
        "# Training the RBM\n",
        "no_epoch = 10\n",
        "for epoch in range(1,no_epoch + 1):\n",
        "    train_loss = 0 # diff b/w pred and actual ratings\n",
        "    s = 0.0\n",
        "    for id_users in range(0,no_users - batch_size,batch_size):\n",
        "        vk = training_set_list[id_users:id_users + batch_size]\n",
        "        v0 = training_set_list[id_users:id_users + batch_size]  # Actual ratings\n",
        "        ph0,_ = rbm.sample_h(v0)\n",
        "        # K-step Contrastive Divergence\n",
        "        for k in range(10):\n",
        "            _,hk = rbm.sample_h(vk)\n",
        "            _,vk = rbm.sample_v(hk)\n",
        "            vk[v0<0] = v0[v0<0]\n",
        "        phk,_ = rbm.sample_h(vk)\n",
        "        rbm.train(v0,vk,ph0,phk)\n",
        "        train_loss += torch.mean(torch.abs(v0[v0>=0]-vk[v0>=0]))\n",
        "        s+=1\n",
        "    print('epoch: ' + str(epoch) + ' loss: ' + str(train_loss/s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 loss: tensor(0.3170)\n",
            "epoch: 2 loss: tensor(0.2568)\n",
            "epoch: 3 loss: tensor(0.2561)\n",
            "epoch: 4 loss: tensor(0.2523)\n",
            "epoch: 5 loss: tensor(0.2492)\n",
            "epoch: 6 loss: tensor(0.2456)\n",
            "epoch: 7 loss: tensor(0.2487)\n",
            "epoch: 8 loss: tensor(0.2493)\n",
            "epoch: 9 loss: tensor(0.2528)\n",
            "epoch: 10 loss: tensor(0.2482)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oC4IGfvkM_G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28f0c4b2-973a-4881-8037-2e00f404d554"
      },
      "source": [
        "# diff b/w pred and actual ratings\n",
        "test_loss = 0 \n",
        "s = 0.0\n",
        "for id_users in range(no_users):\n",
        "    v = training_set_list[id_users:id_users + 1]\n",
        "    vt = test_set_list[id_users:id_users + 1]  # Actual ratings\n",
        "    if len(vt[vt>=0])>0:\n",
        "        _,h = rbm.sample_h(v)\n",
        "        _,v = rbm.sample_v(h)\n",
        "        test_loss += torch.mean(torch.abs(vt[vt>=0]-v[vt>=0]))\n",
        "        s+=1\n",
        "print('test loss:' + str(test_loss/s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test loss:tensor(0.2477)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_A1gXQvagaG",
        "colab_type": "text"
      },
      "source": [
        "# TEST SET III"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLERj6VplY6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "eb4e254f-7701-46f3-88f1-490d6e20b68e"
      },
      "source": [
        "# Preparing the training sets and test sets\n",
        "training_set = pd.read_csv('u3.base',delimiter='\\t')\n",
        "training_set = np.array(training_set,dtype='int')\n",
        "test_set = pd.read_csv('u3.test',delimiter='\\t')\n",
        "test_set = np.array(test_set,dtype='int')\n",
        "print(training_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[        1         2         3 876893171]\n",
            " [        1         3         4 878542960]\n",
            " [        1         4         3 876893119]\n",
            " ...\n",
            " [      943      1188         3 888640250]\n",
            " [      943      1228         3 888640275]\n",
            " [      943      1330         3 888692465]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3INYihUXNUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
        "no_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3B9z7-KlZIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the data into a matrix with users in lines and movies in columns\n",
        "def convert(data):\n",
        "  new_data = []\n",
        "  for id_users in range(1,no_users + 1):\n",
        "    id_movies = data[:,1][data[:,0] == id_users]\n",
        "    id_ratings = data[:,2][data[:,0] == id_users]\n",
        "    ratings = np.zeros(no_movies)\n",
        "    ratings[id_movies-1] = id_ratings\n",
        "    new_data.append(list(ratings))\n",
        "  return new_data\n",
        "training_set_list = convert(training_set)\n",
        "test_set_list = convert(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXKdoJbplZLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Torch Tensors\n",
        "# Input for a Tensor would be a list of lists \n",
        "training_set_list = torch.FloatTensor(training_set_list)\n",
        "test_set_list = torch.FloatTensor(test_set_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIsMtB6MlZWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set_list[training_set_list == 0] = -1\n",
        "training_set_list[training_set_list == 1] = 0\n",
        "training_set_list[training_set_list == 2] = 0\n",
        "training_set_list[training_set_list >= 3] = 1\n",
        "test_set_list[test_set_list == 0] = -1\n",
        "test_set_list[test_set_list == 1] = 0\n",
        "test_set_list[test_set_list == 2] = 0\n",
        "test_set_list[test_set_list >= 3] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4NDdjn3lZZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the architecture of the RBM\n",
        "class RBM():\n",
        "  def __init__(self,nv,nh):\n",
        "    # Initializes the weights of the probs for the visible node given the hidden nodes\n",
        "    self.W = torch.randn(nh,nv) \n",
        "    # Initializes the bias of the probs for the hidden node\n",
        "    self.A = torch.randn(1,nh) \n",
        "    # Initializes the bias of the probs for the visible node\n",
        "    self.B = torch.randn(1,nv) \n",
        "  # Sampling the hidden nodes according to probs P(H/V)\n",
        "  def sample_h(self,x):\n",
        "    # Product of W and x\n",
        "    wx = torch.mm(x,self.W.t())\n",
        "    # To have the same dimensionality as wx appiled at each line of mininbatch wx.\n",
        "    activation = wx + self.A.expand_as(wx) \n",
        "    p_h_given_v = torch.sigmoid(activation)\n",
        "    # Returns bernoulli samples of p_h_given_v distribution\n",
        "    return p_h_given_v,torch.bernoulli(p_h_given_v)\n",
        "  # Sampling the visible nodes according to probs P(V/H)\n",
        "  def sample_v(self,y):\n",
        "    wy = torch.mm(y,self.W) # Product of W and x\n",
        "    activation = wy + self.B.expand_as(wy) # To have the same dimensionality as wx\n",
        "    p_v_given_h = torch.sigmoid(activation)\n",
        "    return p_v_given_h,torch.bernoulli(p_v_given_h)\n",
        "  # Contrastive Divergence\n",
        "  def train(self,v0,vk,ph0,phk):\n",
        "    self.W = self.W + (torch.mm(v0.t(),ph0) - torch.mm(vk.t(),phk)).t()\n",
        "    self.B = self.B + torch.sum((v0 - vk),0)\n",
        "    self.A = self.A + torch.sum((ph0 - phk),0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDcNqiu0lZTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "0f9f3af0-405f-4cef-da0e-a539e5edbc52"
      },
      "source": [
        "# no of movies\n",
        "nv = len(training_set_list[0])\n",
        "# no of features we want to detect\n",
        "nh = 100\n",
        "batch_size = 100\n",
        "# Creating the object\n",
        "rbm = RBM(nv,nh)\n",
        "# Training the RBM\n",
        "no_epoch = 10\n",
        "for epoch in range(1,no_epoch + 1):\n",
        "    train_loss = 0 # diff b/w pred and actual ratings\n",
        "    s = 0.0\n",
        "    for id_users in range(0,no_users - batch_size,batch_size):\n",
        "        vk = training_set_list[id_users:id_users + batch_size]\n",
        "        v0 = training_set_list[id_users:id_users + batch_size]  # Actual ratings\n",
        "        ph0,_ = rbm.sample_h(v0)\n",
        "        # K-step Contrastive Divergence\n",
        "        for k in range(10):\n",
        "            _,hk = rbm.sample_h(vk)\n",
        "            _,vk = rbm.sample_v(hk)\n",
        "            vk[v0<0] = v0[v0<0]\n",
        "        phk,_ = rbm.sample_h(vk)\n",
        "        rbm.train(v0,vk,ph0,phk)\n",
        "        train_loss += torch.mean(torch.abs(v0[v0>=0]-vk[v0>=0]))\n",
        "        s+=1\n",
        "    print('epoch: ' + str(epoch) + ' loss: ' + str(train_loss/s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 loss: tensor(0.3169)\n",
            "epoch: 2 loss: tensor(0.2503)\n",
            "epoch: 3 loss: tensor(0.2496)\n",
            "epoch: 4 loss: tensor(0.2510)\n",
            "epoch: 5 loss: tensor(0.2534)\n",
            "epoch: 6 loss: tensor(0.2499)\n",
            "epoch: 7 loss: tensor(0.2509)\n",
            "epoch: 8 loss: tensor(0.2507)\n",
            "epoch: 9 loss: tensor(0.2522)\n",
            "epoch: 10 loss: tensor(0.2500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94fNj4pSlZQq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2269e51-bd40-40b2-d7f2-9f53f15dc7e8"
      },
      "source": [
        "# diff b/w pred and actual ratings\n",
        "test_loss = 0 \n",
        "s = 0.0\n",
        "for id_users in range(no_users):\n",
        "    v = training_set_list[id_users:id_users + 1]\n",
        "    vt = test_set_list[id_users:id_users + 1]  # Actual ratings\n",
        "    if len(vt[vt>=0])>0:\n",
        "        _,h = rbm.sample_h(v)\n",
        "        _,v = rbm.sample_v(h)\n",
        "        test_loss += torch.mean(torch.abs(vt[vt>=0]-v[vt>=0]))\n",
        "        s+=1\n",
        "print('test loss:' + str(test_loss/s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test loss:tensor(0.2528)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}